#!/usr/bin/env python3

#
# publish_mixed_mode_results.py
#
# This source file is part of the FoundationDB open source project
#
# Copyright 2015-2025 Apple Inc. and the FoundationDB project authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# This script generates a list of mixed-mode testing results generated by the task
# ./gradlew mixedModeTest

import argparse
import subprocess
import sys

def run(command):
    try:
        process = subprocess.run(command, check=True, capture_output=True, text=True)
        return process.stdout
    except subprocess.CalledProcessError as e:
        print("Failed: " + str(e.cmd))
        print(e.stdout)
        print(e.stderr)
        exit(e.returncode)

def get_results(results_path):
    results = {}
    with open(results_path) as f:
        for line in f:
            split = line.strip().split(' ')
            if len(split) != 2:
                raise Exception("Line is not valid: " + line)
            result = split[0]
            version = split[1]
            if result == 'FAILURE':
                results[version] = result
            elif result == 'SUCCESS' and version not in results:
                results[version] = result
    return results

def get_results_from_directory(results_dir):
    import os
    import re
    results = {}
    pattern = re.compile(r'^mixed-mode-(.+)-test-reports-overall.txt$')
    for filename in os.listdir(results_dir):
        match = pattern.match(filename)
        if match is None:
            continue
        version = match.group(1)
        filepath = os.path.join(results_dir, filename)
        with open(filepath) as f:
            result = f.read().strip()
        if result not in ('SUCCESS', 'FAILURE'):
            raise Exception("File " + filepath + " contains invalid result: " + result)
        if result == 'FAILURE':
            results[version] = result
        elif version not in results:
            results[version] = result
    return results

def emoji(result_word):
    if result_word == 'FAILURE':
        return '❌'
    elif result_word == 'SUCCESS':
        return '✅'
    else:
        raise Exception('Invalid result type: ' + result_word)

def generate_markdown(version, results, header_size):
    sorted_keys = sorted(results.keys(), key=lambda raw: [int(part) for part in raw.split('.')])

    return header_size + " Mixed Mode Test Results\n\nMixed mode testing run against the following previous versions:\n\n" + \
        ', '.join([emoji(results[version]) + '`' + version + '`' for version in sorted_keys])

def main(argv):
    '''Process the output of a mixedModeTest run and convert it into a short markdown'''
    parser = argparse.ArgumentParser()
    parser.add_argument('--results-path', help='Path to the results file, or directory when --use-separate-source-files is set', default='.out/reports/mixed-mode-results.log')
    parser.add_argument('--use-separate-source-files', action='store_true', help='Read results from per-version files in a directory instead of a single log file')
    parser.add_argument('--header-size', help='Markdown header level (e.g. # or ##)', default='####')
    parser.add_argument('--run-link', help='A link to the test run that generated the results')
    parser.add_argument('--output', required=True, help='Output to print the markdown to')
    parser.add_argument('version', help='Version of the server that was tested')
    args = parser.parse_args(argv)

    if args.use_separate_source_files:
        results = get_results_from_directory(args.results_path)
    else:
        results = get_results(args.results_path)

    markdown = generate_markdown(args.version, results, args.header_size)
    if args.run_link is not None:
        markdown = markdown + "\n\n[See full test run](" + args.run_link +")\n"
    with open(args.output, mode='w') as fout:
        fout.write(markdown)

if __name__ == '__main__':
    main(sys.argv[1:])
